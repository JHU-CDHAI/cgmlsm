{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85bb0468",
   "metadata": {},
   "source": [
    "# Space Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43aa0790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jluo41/CGMLSM-Project/\n",
      "code/pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jluo41/miniconda3/envs/nix/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import disable_caching; disable_caching()\n",
    "from pprint import pprint\n",
    "KEY = '2-OhioT1DM'\n",
    "WORKSPACE_PATH = os.getcwd().split(KEY)[0]\n",
    "print(WORKSPACE_PATH); os.chdir(WORKSPACE_PATH)\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='[%(levelname)s:%(asctime)s:(%(filename)s@%(lineno)d %(name)s)]: %(message)s')\n",
    "\n",
    "SPACE = {\n",
    "    'DATA_RAW': f'_Data/0-Data_Raw',\n",
    "    'DATA_RFT': f'_Data/1-Data_RFT',\n",
    "    'DATA_CASE': f'_Data/2-Data_CASE',\n",
    "    'DATA_AIDATA': f'_Data/3-Data_AIDATA',\n",
    "    'DATA_EXTERNAL': f'code/external',\n",
    "    'DATA_HFDATA': f'_Data/5-Data_HFData',\n",
    "    'CODE_FN': f'code/pipeline',\n",
    "    'MODEL_ROOT': f'./_Model',\n",
    "}\n",
    "assert os.path.exists(SPACE['CODE_FN']), f'{SPACE[\"CODE_FN\"]} not found'\n",
    "print(SPACE['CODE_FN'])\n",
    "sys.path.append(SPACE['CODE_FN'])\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87bea6b",
   "metadata": {},
   "source": [
    "# Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fedb9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['setname', '000-030min_rMSE', '000-060min_rMSE', '000-120min_rMSE',\n",
      "       '000-030min_rMSE:all', '000-060min_rMSE:all', '000-120min_rMSE:all',\n",
      "       'model_name'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>setname</th>\n",
       "      <th>000-030min_rMSE</th>\n",
       "      <th>000-060min_rMSE</th>\n",
       "      <th>000-120min_rMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CGMOnlyLSM</td>\n",
       "      <td>[test-id]</td>\n",
       "      <td>9.024059</td>\n",
       "      <td>15.894782</td>\n",
       "      <td>26.876165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neural_mlp_i289o24_trials10</td>\n",
       "      <td>[test-id]</td>\n",
       "      <td>14.972304</td>\n",
       "      <td>20.679605</td>\n",
       "      <td>28.683272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neural_transformer_i289o24_trials10</td>\n",
       "      <td>[test-id]</td>\n",
       "      <td>27.886044</td>\n",
       "      <td>30.868808</td>\n",
       "      <td>36.652923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neural_lstm_i289o24_trials10</td>\n",
       "      <td>[test-id]</td>\n",
       "      <td>36.022116</td>\n",
       "      <td>37.169844</td>\n",
       "      <td>38.703427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neural_rnn_i289o24_trials10</td>\n",
       "      <td>[test-id]</td>\n",
       "      <td>36.102312</td>\n",
       "      <td>37.344436</td>\n",
       "      <td>38.951741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>neural_gru_i289o24_trials10</td>\n",
       "      <td>[test-id]</td>\n",
       "      <td>37.555258</td>\n",
       "      <td>38.572921</td>\n",
       "      <td>40.108142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>neural_informer_i289o24_trials10</td>\n",
       "      <td>[test-id]</td>\n",
       "      <td>35.196747</td>\n",
       "      <td>36.962192</td>\n",
       "      <td>40.203870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_autoformer_i289o24_trials10</td>\n",
       "      <td>[test-id]</td>\n",
       "      <td>36.080422</td>\n",
       "      <td>38.351716</td>\n",
       "      <td>41.394727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model_name    setname  000-030min_rMSE  \\\n",
       "1                           CGMOnlyLSM  [test-id]         9.024059   \n",
       "5          neural_mlp_i289o24_trials10  [test-id]        14.972304   \n",
       "3  neural_transformer_i289o24_trials10  [test-id]        27.886044   \n",
       "4         neural_lstm_i289o24_trials10  [test-id]        36.022116   \n",
       "2          neural_rnn_i289o24_trials10  [test-id]        36.102312   \n",
       "7          neural_gru_i289o24_trials10  [test-id]        37.555258   \n",
       "6     neural_informer_i289o24_trials10  [test-id]        35.196747   \n",
       "0   neural_autoformer_i289o24_trials10  [test-id]        36.080422   \n",
       "\n",
       "   000-060min_rMSE  000-120min_rMSE  \n",
       "1        15.894782        26.876165  \n",
       "5        20.679605        28.683272  \n",
       "3        30.868808        36.652923  \n",
       "4        37.169844        38.703427  \n",
       "2        37.344436        38.951741  \n",
       "7        38.572921        40.108142  \n",
       "6        36.962192        40.203870  \n",
       "0        38.351716        41.394727  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '_Model/glucopred_nix_optuna'\n",
    "\n",
    "names = os.listdir(path)\n",
    "\n",
    "\n",
    "li = []\n",
    "for name in names:\n",
    "    try:    \n",
    "        df_eval = pd.read_parquet(os.path.join(path, name, 'eval.parquet'))\n",
    "        df_eval['model_name'] = name\n",
    "        li.append(df_eval)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df = pd.concat(li).reset_index(drop=True)\n",
    "print(df.columns)\n",
    "\n",
    "columns = ['model_name', 'setname', \n",
    "           '000-030min_rMSE',\n",
    "           '000-060min_rMSE', \n",
    "           '000-120min_rMSE',]\n",
    "\n",
    "df_report = df[columns].sort_values(by='000-120min_rMSE')\n",
    "df_report\n",
    "\n",
    "# OhioT1DM\t9.358 (0.684)\t15.64 (1.078)\t26.296 (1.664)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "848df5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['unique_id', 'Inputs', 'Real', 'Predict', 'prediction_time', 'stratum',\n",
      "       'Splitname', 'model_name', 'split_timebin', 'prediction_hour',\n",
      "       'age_interval', 'gender', 'diabetes_type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "path = '_Model/glucopred_nix_optuna'\n",
    "\n",
    "names = os.listdir(path)\n",
    "\n",
    "\n",
    "li = []\n",
    "for name in names:\n",
    "    try:    \n",
    "        df_predictions = pd.read_parquet(os.path.join(path, name, 'df_predictions.parquet'))\n",
    "        df_predictions['model_name'] = name\n",
    "        li.append(df_predictions)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df_predictions_all = pd.concat(li).reset_index(drop=True)\n",
    "print(df_predictions_all.columns)\n",
    "\n",
    "# OhioT1DM\t9.358 (0.684)\t15.64 (1.078)\t26.296 (1.664)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22106b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rMSE', 'MAE', 'MAEWithin5', 'RegionAccu', 'TIR_error']\n"
     ]
    }
   ],
   "source": [
    "from nn.eval.seqeval import SeqEvalForOneEvalSet\n",
    "\n",
    "OUTPUT_LENGTH = 24\n",
    "\n",
    "horizon_to_se = {\n",
    "    '30m': [0, 6],\n",
    "    '1h': [0, 12],\n",
    "    '2h': [0, 24],\n",
    "}\n",
    "CURRENT_POINT = 289 \n",
    "\n",
    "metric_list = [\n",
    "    'rMSE', # y_pred, y_real\n",
    "    'MAE', \n",
    "    \n",
    "    'MAEWithin5',\n",
    "    'RegionAccu',\n",
    "\n",
    "    'TIR_error', # y_pred, y_real\n",
    "] \n",
    "\n",
    "evaluator = SeqEvalForOneEvalSet(\n",
    "    setname = 'all',\n",
    "    df_case_eval = df_predictions_all,\n",
    "    x_hist_seq_name = 'Inputs',\n",
    "    y_real_seq_name = 'Real',\n",
    "    y_pred_seq_name = 'Predict',\n",
    "    metric_list = metric_list,\n",
    "    horizon_to_se = horizon_to_se,\n",
    ")\n",
    "\n",
    "df_case_metric, metric_list = evaluator.get_df_case_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9aa23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case = df_case_metric\n",
    "df_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcce0bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import sem, t\n",
    "\n",
    "def get_case_inoutsplit(x):\n",
    "    if x['Train'] == True:\n",
    "        TVT = '0.Train'\n",
    "    elif x['Valid'] == True:\n",
    "        TVT = '1.Internal Test'\n",
    "    elif x['Test'] == True:\n",
    "        TVT = '2.Temporal Test'\n",
    "    else:\n",
    "        print(x['Train'], x['Valid'], x['Test'])\n",
    "        pass \n",
    "\n",
    "    if x['In'] == True:\n",
    "        InOut = 'In'\n",
    "    elif x['Out'] == True:\n",
    "        InOut = 'Out'\n",
    "    else:\n",
    "        pass\n",
    "    split = InOut + '-' + TVT\n",
    "    if InOut == 'Out':\n",
    "        split = '3.Hold-Out Test'\n",
    "    elif InOut == 'In':\n",
    "        split = TVT\n",
    "    return split\n",
    "\n",
    "\n",
    "def map_age_to_group_v1(x):\n",
    "    if x < 18:\n",
    "        return 'O: 18'\n",
    "    elif 18 <= x < 40:\n",
    "        return 'A: 18-39'\n",
    "    elif 40 <= x < 65:\n",
    "        return 'B: 40-64'\n",
    "    # elif 65 <= x < 80:\n",
    "    #     return 'C: 65-79'\n",
    "    # elif x >= 80:\n",
    "    #     return 'D: 80+'\n",
    "    elif x >= 65:\n",
    "        return 'C: 65+'\n",
    "\n",
    "\n",
    "def map_TIR_to_region(x):\n",
    "    if 0 < x <= 0.2:\n",
    "        return '5: OutRange-VeryHigh'\n",
    "    elif 0.2 < x <= 0.4:\n",
    "        return '4: OutRange-High'\n",
    "    elif 0.4 < x <= 0.6:\n",
    "        return '3: OutRange-Medium'\n",
    "    elif 0.6 < x <= 0.8:\n",
    "        return '2: OutRange-Low'\n",
    "    elif 0.8 < x <= 1:\n",
    "        return '1: OutRange-VeryLow'\n",
    "    \n",
    "\n",
    "\n",
    "def evaluate_df_with_metric(df, metric_name):\n",
    "    # df should have a name\n",
    "    metric_values = df[metric_name]\n",
    "    d = {}\n",
    "    d['metric_name'] = metric_name\n",
    "    d['mean'] = metric_values.mean()\n",
    "    d['sem'] = sem(metric_values)\n",
    "    d['ci'] = d['sem'] * t.ppf((1 + 0.95) / 2, len(metric_values) - 1)\n",
    "\n",
    "    # Number of bootstrap samples\n",
    "    n_bootstrap = 10000\n",
    "    bootstrap_means = np.empty(n_bootstrap)\n",
    "    # Perform bootstrap sampling\n",
    "    for i in range(n_bootstrap):\n",
    "        # Resample with replacement\n",
    "        bootstrap_sample = np.random.choice(metric_values, size=len(metric_values), replace=True)\n",
    "        # Calculate the mean of the bootstrap sample\n",
    "        bootstrap_means[i] = np.mean(bootstrap_sample)\n",
    "\n",
    "    # Calculate the bootstrap confidence interval\n",
    "    confidence_level = 0.95\n",
    "    lower_percentile = (1 - confidence_level) / 2 * 100\n",
    "    upper_percentile = (1 + confidence_level) / 2 * 100\n",
    "    confidence_interval = np.percentile(bootstrap_means, [lower_percentile, upper_percentile])\n",
    "    # Calculate the bootstrap mean RMSE\n",
    "    mean_rmse_bootstrap = np.mean(bootstrap_means)\n",
    "\n",
    "    d['ci_bootstrap'] = confidence_interval\n",
    "    d['mean_bootstrap'] = mean_rmse_bootstrap\n",
    "    return d\n",
    "\n",
    "\n",
    "\n",
    "metric_columns = [\n",
    "        # 'rMSE_30Min', 'rMSE_1stH', 'rMSE_2ndH', 'rMSE_2H', \n",
    "        # 'MAE_30Min', 'MAE_1stH', 'MAE_2ndH', 'MAE_2H',\n",
    "        # 'MAEWithin5_30Min', 'MAEWithin5_1stH', 'MAEWithin5_2ndH', 'MAEWithin5_2H', \n",
    "        # 'MAEWithin10_30Min', 'MAEWithin10_1stH', 'MAEWithin10_2ndH', 'MAEWithin10_2H', \n",
    "        # 'RegionAccu_30Min', 'RegionAccu_1stH', 'RegionAccu_2ndH', 'RegionAccu_2H',\n",
    "\n",
    "       '30m_rMSE', '30m_MAE', '30m_TIR_error',\n",
    "       '1h_rMSE', '1h_MAE', '1h_TIR_error', \n",
    "       '2h_rMSE', '2h_MAE', '2h_TIR_error'\n",
    "\n",
    "    ]\n",
    "\n",
    "def process_report_allmetrics(df, metric_columns):\n",
    "    df = df.copy()\n",
    "    L = []\n",
    "    for metric_column in metric_columns:\n",
    "        d = evaluate_df_with_metric(df, metric_column)\n",
    "        L.append(d)\n",
    "\n",
    "    df_report = pd.DataFrame(L) \n",
    "    return df_report\n",
    "\n",
    "\n",
    "def process_report(df, metric_columns = metric_columns):\n",
    "    df = df.copy()\n",
    "    columns_y = ['30m', '1h', '2h']\n",
    "    columns_x = ['rMSE', 'MAE',  'TIR_error']\n",
    "\n",
    "    # L = []\n",
    "    # for metric_column in metric_columns:\n",
    "    #     d = evaluate_df_with_metric(df, metric_column)\n",
    "    #     L.append(d)\n",
    "    # df_report = pd.DataFrame(L) \n",
    "\n",
    "    # Calculate mean, SEM, and counts\n",
    "    df_mean = df[metric_columns].mean().reset_index()\n",
    "    df_sem = df[metric_columns].sem().reset_index()\n",
    "    df_count = df[metric_columns].count().reset_index()\n",
    "\n",
    "\n",
    "\n",
    "    # Calculate 90% CI\n",
    "    confidence_level = 0.95\n",
    "    df_ci = df_sem.copy()\n",
    "    for i in range(len(df_ci)):\n",
    "        n = df_count.iloc[i, 1]\n",
    "        critical_t = t.ppf((1 + confidence_level) / 2, n - 1)\n",
    "        df_ci.iloc[i, 1] = df_sem.iloc[i, 1] * critical_t\n",
    "\n",
    "    # Organize data\n",
    "    d = {'mean': df_mean, 'sem': df_sem, 'ci': df_ci}\n",
    "    results = {}\n",
    "    # results['size'] = len(df)\n",
    "\n",
    "    # print('the size of the dataset is:', len(df), 'human', df['PID'].nunique())\n",
    "    for name, df_r in d.items():\n",
    "        df_r.rename(columns={0: 'Score', 'index': 'FullMetric'}, inplace=True)\n",
    "        df_r['horizon'] = df_r['FullMetric'].apply(lambda x: x.split('_')[0].strip())\n",
    "        df_r['Metric']  = df_r['FullMetric'].apply(lambda x: '_'.join(x.split('_')[1:]).strip())\n",
    "        df_r = df_r.pivot(index='horizon', columns='Metric', values='Score')\n",
    "        df_r = df_r[columns_x].T\n",
    "        df_r = df_r[columns_y]\n",
    "        results[name] = df_r\n",
    "    return results\n",
    "\n",
    "\n",
    "def process_performance_output(df, \n",
    "                               subcolumns_list, \n",
    "                               focus_on_list, \n",
    "                               metric, \n",
    "                               horizon):\n",
    "    L_mean = []\n",
    "    L_sem  = []\n",
    "    L_ci   = []\n",
    "    for subcolumns in subcolumns_list:\n",
    "        for subname, df_sub in df.groupby(subcolumns):\n",
    "            name = ['.'.join([str(s) for s in i]) for i in list(zip(subcolumns, subname))]\n",
    "            name = '_'.join(name)\n",
    "            if len(focus_on_list) > 0:\n",
    "                indicator = np.mean([focus_on in name for focus_on in focus_on_list])\n",
    "                if indicator != 1: continue\n",
    "\n",
    "            print('current name is :', name)\n",
    "            results = process_report(df_sub)\n",
    "\n",
    "            df_r = results['mean']\n",
    "            v = df_r.loc[metric, horizon]\n",
    "            metric_name = '-'.join([metric, horizon])\n",
    "            d = {'name': name, metric_name: v}\n",
    "            for k, v in list(zip(subcolumns, subname)): d[k] = v\n",
    "            L_mean.append(d)\n",
    "\n",
    "            df_r = results['sem']\n",
    "            v = df_r.loc[metric, horizon]\n",
    "            metric_name = '-'.join([metric, horizon])\n",
    "            d = {'name': name, metric_name: v}\n",
    "            for k, v in list(zip(subcolumns, subname)): d[k] = v\n",
    "            L_sem.append(d)\n",
    "\n",
    "\n",
    "            df_r = results['ci']\n",
    "            v = df_r.loc[metric, horizon]\n",
    "            metric_name = '-'.join([metric, horizon])\n",
    "            d = {'name': name, metric_name: v}\n",
    "            for k, v in list(zip(subcolumns, subname)): d[k] = v\n",
    "            L_ci.append(d)\n",
    "            \n",
    "    df_mean = pd.DataFrame(L_mean)\n",
    "    df_sem = pd.DataFrame(L_sem)\n",
    "    df_ci = pd.DataFrame(L_ci)\n",
    "\n",
    "    report_results = {'mean': df_mean, 'sem': df_sem, 'ci': df_ci}\n",
    "    return report_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8225db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "metric = 'rMSE'\n",
    "###############\n",
    "\n",
    "subcolumns_list = [\n",
    "    ['model_name']\n",
    "]\n",
    "focus_on_list = []\n",
    "horizon_list = ['30m', '1h', '2h']\n",
    "\n",
    "\n",
    "final_results = {'mean': [], 'sem': [], 'ci': []}\n",
    "for horizon in horizon_list:\n",
    "    results = process_performance_output(df_case, subcolumns_list, focus_on_list, metric, horizon)\n",
    "    value_name = f'{metric}-{horizon}'\n",
    "    subcolumns = subcolumns_list[0]\n",
    "    index = subcolumns[0]\n",
    "    columns = subcolumns[1:]\n",
    "    for name, dfx in results.items():\n",
    "        dfx = dfx.rename(columns = {value_name: 'Value'})\n",
    "        dfx['ValueName'] = value_name\n",
    "        final_results[name].append(dfx)\n",
    "\n",
    "df_mean = pd.concat(final_results['mean'])\n",
    "df_sem  = pd.concat(final_results['sem'])\n",
    "df_ci  = pd.concat(final_results['ci'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c13df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e998eb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Topic = metric\n",
    "\n",
    "d = {'mean': df_mean, 'ci': df_ci}\n",
    "results = {}\n",
    "for name, dfx in d.items():\n",
    "    dfx = dfx.pivot(index = ['model_name'], columns = 'ValueName', values = 'Value')\n",
    "    print(dfx.columns)\n",
    "    custom_order = [f'{metric}-{i}' for i in ['30m', '1h', '2h']]\n",
    "\n",
    "    dfx = dfx.reindex(columns=custom_order)\n",
    "    # dfx.to_pickle(path)\n",
    "    dfx.loc[:, custom_order] = dfx.loc[:, custom_order].round(3)\n",
    "    results[name] = dfx\n",
    "\n",
    "    # new_path = path.replace('.p', f'_{name}.p')\n",
    "    # dfx.to_pickle(new_path)\n",
    "    # print(new_path)\n",
    "    display(dfx)\n",
    "\n",
    "\n",
    "# name = 'ci' # 'mean'\n",
    "# results[name].to_clipboard()\n",
    "\n",
    "df_mean = results['mean']\n",
    "df_ci = results['ci']\n",
    "\n",
    "df_full = df_mean.copy()\n",
    "for column in custom_order:\n",
    "    df_full[column] = df_mean[column].astype(str) + \" (\" + df_ci[column].astype(str) + \")\"\n",
    "\n",
    "# df_full.to_clipboard()  \n",
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9e0e55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
